# RL Energy Management Systems Project

Welcome to our Reinforcement Learning (RL) project, an exploration into the fascinating world of RL applied to Energy Management Systems (EMS). Our team is excited to collaborate on this initiative, and we extend our gratitude to TotalEnergies, a leading French energy company, for their generous support and resources.

## Project Overview

Our primary objective is to develop a Jupyter/Colab notebook as a comprehensive platform for experimenting with RL algorithms, specifically focusing on Q-learning and Deep Q Learning. Leveraging the pymgrid Python library provided by TotalEnergies, our project aims to simulate diverse microgrid scenarios. This simulation environment allows us to develop intelligent algorithms capable of autonomously enhancing energy supply management strategies.

### Role of pymgrid

TotalEnergies' contribution, through the pymgrid Python library, has been instrumental to our project's success. This library enables the generation and simulation of a large number of microgrids, providing a realistic and scalable environment for testing RL algorithms. The versatility of pymgrid allows us to explore and fine-tune our algorithms under various conditions, making it an invaluable asset to our project.

## Agent's Mission

At the heart of our project is the pivotal role of the agent. Tasked with finding an efficient strategy for energy utilization, the agent considers key factors such as environmental impact, frugality, and financial aspects. The overarching goal is to reduce the final energy cost while concurrently optimizing the use of resources.

## Algorithmic Approach: Q-learning and Deep Q Learning

Our strategic choice of Q-learning and Deep Q Learning as primary algorithms stems from their proven efficacy in RL applications. Q-learning facilitates adaptive decision-making based on interactions with the environment, while Deep Q Learning extends these capabilities by incorporating deep neural networks. This combination enables our agent to navigate complex scenarios and dynamically optimize energy supply strategies.

## Conclusion

In conclusion, our project represents a dedicated effort to bridge the gap between theoretical RL concepts and real-world challenges in energy management. We are excited about the potential impact of our work and look forward to contributing valuable insights to the field.

Feel free to explore our code and documentation in the provided Jupyter/Colab notebook. We appreciate your interest and welcome any feedback or collaboration opportunities.

Happy coding!
q
## Sources

To deepen our understanding of RL in energy management, we've consulted the following sources:

1. "Training an Energy Decision Agent With Reinforcement Learning" - [Towards Data Science Article](https://towardsdatascience.com/training-an-energy-decision-agent-with-reinforcement-learning-a7567b61d0aa)

2. "Applications of reinforcement learning in energy systems" - [Research Paper](https://www.sciencedirect.com/science/article/pii/S1364032120309023?ref=pdf_download&fr=RR-2&rr=8238bd155dfb4bcb)

3. "Deep reinforcement learning for energy management in a microgrid with flexible demand" - [Research Paper](https://www.sciencedirect.com/science/article/pii/S2352467720303441?ref=pdf_download&fr=RR-2&rr=8238bf405bdb4bcb)

4. "Reinforcement Learning Based Energy Management Algorithm for Smart Energy Buildings" - [Research Paper](https://www.mdpi.com/1996-1073/11/8/2010)

5. "Environment to simulate microgrids" - [GitHub Repository](https://github.com/Total-RD/pymgrid)
